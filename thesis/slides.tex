\documentclass{beamer}
\usepackage{mathtools,amsthm,bm}
\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}

\usepackage[noend]{algpseudocode}
\usepackage{algorithm}
\newcommand*\Let[2]{\State #1 $\gets$ #2}
\newcommand*{\TO}{\textbf{to}}
% since gemm3 can't be a matro name
\newcommand*{\pluseq}{\mathrel{{+}{=}}}
\newcommand*{\gemmt}{{\textsc{gemm3}}}
\newcommand*{\gemm}{{\textsc{gemm}}}

\usepackage{hyperref}

\usepackage{graphicx}
\usepackage{adjustbox}

\usepackage{tikz}
\usetikzlibrary{matrix,arrows.meta,calc,fit,positioning,chains,shapes}
\input{libgemmpicture}

\tikzset{
  invisible/.style={opacity=0,text opacity=0},
  visible on/.style={alt={#1{}{invisible}}},
  alt/.code args={<#1>#2#3}{%
    \alt<#1>{\pgfkeysalso{#2}}{\pgfkeysalso{#3}} % \pgfkeysalso doesn't change the path
  },
  explanation/.style={visible on=<2->},
  graph-pic/.style={anchor=north west, at={(0, 0)},inner sep=0pt}
}

\useoutertheme{infolines}
\setbeamertemplate{navigation symbols}{}

\title[\gemmt{}]{\gemmt{}: Constant-workspace high-performance multiplication of three matrices for matrix chaining}
\author[Drewniak]{Krzysztof A. Drewniak}
\institute[UT Austin]{The University of Texas at Austin}
\date[]{April 13, 2018}

\begin{document}
\begin{frame}[plain]
  \titlepage{}
\end{frame}

\section[Introduction]{Introduction}
\begin{frame}
  \frametitle{Matrix chaining problem}
  \begin{itemize}
  \item Problem: compute $A_1A_2\cdots A_n$ efficiently
  \item $O(n \log n)$ algorithm, also $O(n^3)$ with dynamic programming
  \item Fewer flops $\to$ more performance?
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Generalized matrix chaining}
  \begin{itemize}
  \item In reality --- transposes, inverses, properties
  \item
    \begin{description}
    \item[Ensemble Kalman filter] $X_i^b S_i (Y_i^b)^T R_i^{-1}$
    \item[Tridiagonalization] $\tau_u\tau_vvv^TAuu^T$
    \item[Two-sided triangular solve] $L^{-1}AL^{-H}$ ($L$ lower triangular)
    \end{description}
  \item Performance with BLAS/LAPACK -- must be expert
  \item Less performance with  Matlab, numpy, etc. (left-to-right)
  \item Linnea: expression $\to$ BLAS calls automagically
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{\gemmt{} --- Why bother?}
  \begin{itemize}
  \item
    \begin{itemize}
    \item $\bm{X_i^b S_i (Y_i^b)^T}R_i^{-1}$
    \item $\tau_u\tau_v \bm{vv^TAuu^T}$
    \item$\bm{L^{-1}A(L^{-1})^H}$ ($L$ lower triangular)
    \end{itemize}
  \item All multiply three matrices as a subproblem
  \item (Notation: $G \pluseq DEF$ and \gemmt{})
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{\gemmt{} --- Why a new algorithm?}
  \begin{itemize}
  \item Current approach: parentheses, multiply twice, store temporary $T$
  \item $T$ often eats memory (\& perf)
  \item We can do better!
  \item Use how \gemm{} works to nest computations
  \item $O(1)$ extra memory, maybe more performance
  \end{itemize}
\end{frame}

\section[\gemm{}]{High-Performance \gemm{}}
\frame{\sectionpage}

\begin{frame}
  \frametitle{Memory hierarchy}
  \begin{tikzpicture}[read-point/.style={single arrow,minimum height=0.7cm, minimum width=0.1cm, draw, shape border rotate=270}]
    \matrix [matrix of nodes, nodes={draw}, row sep=4pt] {
      |[memory, minimum width=8cm]| Memory\\
      |[read-point]|\\
      |[l3, minimum width=4cm]| $L3$\\
      |[read-point]|\\
      |[l2, minimum width=1.5cm]| $L2$\\
      |[read-point]|\\
      |[l1, minimum width=0.9cm]| $L1$\\
      |[read-point]|\\
      |[regs, minimum width=0.2cm, label=right:Registers]|\\
    };
  \end{tikzpicture}
\end{frame}

\begin{frame}
  \frametitle{Important matrix shapes}
  \begin{adjustbox}{max size={!}{0.87\textheight},center}
  \begin{tikzpicture}
    \matrix (pics)[column sep=0.2cm, row sep=5.5ex, ampersand replacement=\&] {
      \node[square-mat] {Block};\\
      \node[wide-mat] {Row panel};\\
      \node[tall-mat,label={right:Column panel}] {};\\
    };
  \end{tikzpicture}
  \end{adjustbox}
\end{frame}

\begin{frame}
  \frametitle{\gemm{}: The kernels}
  \begin{adjustbox}{max size={!}{0.87\textheight},center}
  \begin{tikzpicture}
    \input{macrokernel-picture}
    \path let \p{north} = (2-loop.north),
    \p{west} = (2-rect-west),
    \p{east} = (2-rect-east)
    in node [fit={(\x{west}, \y{north}) (1B1.south east) (\x{east}, \y{north})},
    fill=white, opacity=0.3, visible on=<-1>] (hide-square) {}
    coordinate [visible on=<2->] (dummy-coord);
  \end{tikzpicture}
  \end{adjustbox}
\end{frame}

\begin{frame}
  \frametitle{\gemm{}: The algorithm}
  \begin{adjustbox}{max size={!}{0.87\textheight},center}
  \begin{tikzpicture}
    \input{blis-picture}
  \end{tikzpicture}
  \end{adjustbox}
\end{frame}


\begin{frame}
  \frametitle{Data reuse}
  \begin{itemize}
  \item Every loop reads \emph{something} repeatedly
  \item Relevant things: packed blocks --- making them takes time
  \item Packed block reuse problems:
    \begin{itemize}
    \item $m$ small --- low time between remakes of $\widetilde{B}$
    \item $n$ small --- same for $\widetilde{A}$
    \item $k$ tiny --- microkernel doesn't do much, small caches
    \end{itemize}
  \end{itemize}
\end{frame}

\section[\gemmt{}]{The \gemmt{} algorithm}
\frame{\sectionpage}

\begin{frame}
  \frametitle{Key concept of the algorithm}
  \begin{itemize}
  \item We want $G \pluseq DEF$, (dimensions: $m, k, l, n$ in order)
  \item $EF$ first needed in packing step
  \item Compute a block then
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Deriving \gemmt{}: Partitionings}
  \begin{adjustbox}{max size={!}{0.87\textheight},center}
  \begin{tikzpicture}
    \matrix (pics)[column sep=0.2cm, row sep=5.5ex, ampersand replacement=\&] {
      \&
      \node[at={(1.5, 0)}] {\large $G$};\&
      \node[at={(0, 0)}] {\large $\pluseq$};\&
      \node[at={(1.5, 0)}] {\large $D$};\&
      \node[at={(1.5, 0)}] {\large $[(EF)$};\&
      \node[at={(0, 0)}] {\large $\leftrightarrow$};\&
      \node[at={(1.5, 0)}] {\large $E$};\&
      \node[at={(1.5, 0)}] {\large $F]$};\\

      \node[at={(0, -1.5)}] {\large 1.};\&
      \node[square-mat] (2G) {\large $m \times n$};\&
      \pluseqnode{2}\&
      \node[square-mat] (2D) {\large $m \times k$};\&
      \node[square-mat, dotted] (2EF) {\large $k \times n$};
      \bracelabel{2EF.north west}{2EF.south west}{left}{}\&
      \node[at={(0, -1.5)}] {\large $\leftrightarrow$};\&
      \node[square-mat] (2E) {\large $k \times l$};\&
      \node[square-mat] (2F) {\large $l \times n$};
      \bracelabel{2F.north east}{2F.south east}{right}{}\\

      \node[at={(0, -1.5)}] {\large 2.};\&
      \node[square-mat] (1G) {\large $m \times n_C$};\&
      \pluseqnode{1}\&
      \node[square-mat] (1D) {\large $m \times k$};\&
      \node[square-mat, dotted] (1EF) {\large $k \times n_C$};
      \bracelabel{1EF.north west}{1EF.south west}{left}{}\&
      \node[at={(0, -1.5)}] {\large $\leftrightarrow$};\&
      \node[square-mat] (1E) {\large $k \times l$};\&
      \node[square-mat] (1F) {\large $l \times n_C$};
      \bracelabel{1F.north east}{1F.south east}{right}{}\\

      \node[at={(0, -1.5)}] {\large 3.};\&
      \node[square-mat] (0G) {\large $m \times n_C$};\&
      \pluseqnode{0}\&
      \node[tall-mat] (0D) {\large $m \times k_C$};\&
      \node[wide-mat, dotted] (0EF) {\large $k_C \times n_C$};
      \bracelabel{0EF.north west}{$(0, -3)$}{left}{}\&
      \node[at={(0, -1.5)}] {\large $\leftrightarrow$};\&
      \node[wide-mat] (0E) {\large $k_C \times l$};\&
      \node[square-mat] (0F) {\large $l \times n_C$};
      \bracelabel{0F.north east}{0F.south east}{right}{}\\
    };
  \end{tikzpicture}
  \end{adjustbox}
\end{frame}

\begin{frame}
  \frametitle{Deriving \gemmt{}: Inner algorithm}
  \begin{adjustbox}{max size={!}{0.5\textheight},center}
  \begin{tikzpicture}
    \matrix (pics)[column sep=0.2cm, row sep=5.5ex, ampersand replacement=\&] {
      \node[wide-mat, l3] (0EF) {\large $\widetilde{EF} \colon k_C \times n_C$};\&
      \node[at={(0, -0.5)}] {\large $=$};\&
      \node[wide-mat] (0E) {\large $E \colon k_C \times l$};\&
      \node[square-mat] (0F) {\large $F \colon l \times n_C$};\\
    };
  \end{tikzpicture}
  \end{adjustbox}
  \begin{itemize}
  \item Only point to compute $EF$ in constant memory
  \item \gemm{} algorithm needs tweaks
  \end{itemize}

\end{frame}

\begin{frame}
  \frametitle{Deriving \gemmt{}: The tricky bits}
  \begin{table}
    \centering
    \begin{tabular}{l|l}
      Problem&Solution\\ \hline \hline
      Redundant loop over $n$ ($n \leq n_C$) & Remove it\\
      Packing output wastes space/time & Tweak microkernel params\\
      $\widetilde{F}$ fights $\widetilde{EF}$ in $L3$ & Halve $n_C$\\
      Low $\widetilde{F}$ reuse & Low impact in practice\\
      $m_R \nmid k_C$, leaving fringe & Shrink $k_C$ slightly\\
    \end{tabular}
    \caption{Tweaks needed to make \gemm{} fusion work}
    \label{tab:gemm3-issues}
  \end{table}
\end{frame}

\begin{frame}
  \frametitle{The algorithm}
  \begin{figure}
    \centering
    \includegraphics[height=0.875\textheight]{gemm3-picture}
    \caption{Illustration of the \gemmt{} algorithm}
    \label{fig:gemm3}
\end{figure}
\end{frame}

\begin{frame}
  \frametitle{$G \pluseq (DE)F$}
  \begin{itemize}
  \item Putting parentheses there sometimes better
  \item Deriving directly doesn't work --- bad shape
  \item However, $G \pluseq (DE)F \Leftrightarrow G^T \pluseq F^T(E^TD^T)$
  \end{itemize}
\end{frame}

\section[Results]{Experiments and Results}
\frame{\sectionpage}

\begin{frame}
  \frametitle{Implementation details}
  \begin{columns}
    \begin{column}{0.5\textwidth}
      \begin{itemize}
      \item Multilevel Optimization of Matrix Multiply Sandbox (MOMMS)
      \item Extended to support three matrices
      \item Implement both \gemmt{} and BLIS algorithm
      \item BLIS algorithm port performs like BLIS
      \item Experiments on Haswell machine from UT lab
      \end{itemize}
    \end{column}
    \begin{column}{0.5\textwidth}
      \begin{table}
        \centering
        \begin{tabular}{l|c c}
          &\gemmt{}&BLIS algorithm\\ \hline
          $m_C$&72&72\\
          $k_C$&252&256\\
          $l_C$&256&\\
          $n_C$&2040&4080\\
        \end{tabular}
        \caption{Parameters for Haswell CPUs}
        \label{tab:haswell-paramss}
      \end{table}
    \end{column}
  \end{columns}
\end{frame}

\begin{frame}
  \frametitle{Experiments}
  \begin{enumerate}
  \item $G \pluseq D(EF)$, square matrices
    \begin{itemize}
    \item Inputs column-major, outputs row-major for fairness
    \end{itemize}
  \item $G^T \pluseq F^T(E^TD^T)$, square matrices
    \begin{itemize}
    \item After transpose, all row major
    \end{itemize}
  \item $G \pluseq D(EF)$, rectangles (one dimension small)
  \end{enumerate}
\end{frame}

\begin{frame}
  \frametitle{Workspace usage, square matrices}
  \begin{tikzpicture}
    \node[graph-pic] (graph) {\includegraphics[height=0.9\textheight]{../results/earwig2/gemm3_memory}};
  \end{tikzpicture}
\end{frame}

\begin{frame}
  \frametitle{$G \pluseq D(EF)$, square matrices}
  \begin{tikzpicture}
    \node[graph-pic] (graph) {\includegraphics[height=0.9\textheight]{../results/earwig2/gemm3}};
    \node[explanation, right=1.5cm of graph.west] {\small Less packing};
    \node[explanation, below left=1.6cm and 3pt of graph.north,anchor=north] {\small Suboptimal shape};
    \node[explanation, below left=2cm and 1cm of graph.north east, anchor=east] {\small Memop overhead};
  \end{tikzpicture}
\end{frame}

\begin{frame}
  \frametitle{$G \pluseq (DE)F$, square matrices}
  \begin{tikzpicture}
    \node[graph-pic] (graph) {\includegraphics[height=0.9\textheight]{../results/earwig2/gemm3_ab_bc_kernel}};
    \node[explanation, at=(graph.center)] {\small Similar trends, row-major helps BLIS};
  \end{tikzpicture}
\end{frame}

\begin{frame}
  \frametitle{$G \pluseq D(EF)$, rectangular matrices}
  \begin{tikzpicture}
    \node[graph-pic] (graph) {\includegraphics[height=0.9\textheight]{../results/earwig2/gemm3_rectangles}};
  \end{tikzpicture}
\end{frame}

\section{Conclusions}
\begin{frame}
  \frametitle{Conclusions}
  \begin{itemize}
  \item \gemm{} structure lets us make \gemmt{}
  \item Constant memory
  \item Comprable performance
  \item Cleaner API
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Future Work}
  \begin{itemize}
  \item Parallel case
  \item More architectures
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Acknowledgments}
  \begin{itemize}
  \item Prof.\ Robert van de Geijn --- advising and providing inspiration
  \item Dr.\ Tyler Smith --- writing MOMMS and algorithm design
  \item Prof.\ Tze Meng Low --- performance fixes
  \item NSF grant \textbf{TODO NNNNNNN} --- funding
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Questions?}
\end{frame}

\section{Picking parameters}
\begin{frame}
  \frametitle{Picking parameters: $m_R, n_R$}
  \begin{itemize}
  \item Determine microkernel
  \item Based on microarchitecture --- register width, FMA properties
  \item We're reusing BLIS's work
  \item Can swap $m_R$ and $n_R$
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Picking parameters: $k_C$}
  Placing memory in cache: [tag][set \#][offset in line]

  \begin{equation*}
    m_rk_cS_{elem} = C_AC_{L1}N_{L1} \qquad n_rk_CS_{elem} = C_BC_{L1}N_{L1}
  \end{equation*}

  \begin{columns}
    \begin{column}{0.1\textwidth}
      L1 Cache:
    \end{column}
    \begin{column}{0.5\textwidth}
      \centering
      \begin{tikzpicture}
        \matrix (labels) [matrix of math nodes, ampersand replacement=\&] {
          A \& A \& B \& B\\
          A \& B \& B \& C\\
        };
        \node[draw, ellipse, fit={(labels-1-1) (labels-2-4)}] (labels-border) {};
        \node[right=5pt of labels-border] {$\ldots$};
      \end{tikzpicture}
    \end{column}
    \begin{column}{0.25\textwidth}
      \begin{equation*}
        C_A + C_B + 1 \leq W_{L1}
      \end{equation*}
    \end{column}
  \end{columns}
  \begin{center}
    Maximizing $k_C$ improves performance
  \end{center}

  \begin{align*}
    C_B &= \ceil*{\frac{n_Rk_CS_{elem}}{N_{L1}C_{L1}}}\\
        &= \ceil*{\frac{n_R}{m_R}C_A}\\
    C_A &\leq \floor*{\frac{W_{L1} - 1}{1 + \frac{n_R}{m_R}}}
  \end{align*}
\end{frame}

\begin{frame}
  \frametitle{Picking parameters: $m_C$ and $n_C$}
  \begin{itemize}
  \item For $m_C$: reserve ways for $B$ and $C$
  \item Then take all you can
  \item $n_C$, leave out what architecture requires, then divide
  \item L3 is very big, tuning is much less needed
  \end{itemize}
\end{frame}
\end{document}
