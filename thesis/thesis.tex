\documentclass[12pt]{article}

\usepackage{mathtools,amsthm}
\usepackage{fontspec}
\usepackage{microtype}

\usepackage[noend]{algpseudocode}
\usepackage{algorithm}
\newcommand*\Let[2]{\State #1 $\gets$ #2}
% since gemm3 can't be a matro name
\newcommand{\pluseq}{\mathrel{{+}{=}}}
\newcommand{\gemmt}{{\texttt{gemm3()}}}
\newcommand{\gemm}{{\texttt{gemm()}}}

\title{gemm3(): Constant-workspace high-performance multiplication of three matrices}
\author{Krzysztof A. Drewniak, Tyler M. Smith, Robert van de Gejin}

\begin{document}
\maketitle{}
\section{Introduction}
High-performance matrix multiplication is an important primitive for high-performance computing.
Significant research effort, both academic (\textbf{TODO cite a few}) and commercial has gone in to optimizing this operation.
The typical interface for such multiplication is the function \gemm{} from the Basic Linear Algebra Subprograms (BLAS) specification, which computes $C \coloneqq \beta C + \alpha AB$ for matrices $A$, $B$, and $C$ and scalars $\alpha$ and $\beta$, optionally taking the transpose of one or both of the input operands.

In several applications, such as \textbf{TODO, I think there's a chemistry thing Devin would know about} and \textbf{TODO another application}, operations of the form $D \coloneqq \beta D + \alpha ABC$ occur.
To perform this (which we'll summarize as $D \pluseq ABC$) performantly using \gemm{}, the programmer must allocate a temporary buffer $T$ and perform $T = BC; D \pluseq AT$ (or $T = AB; D \pluseq TC$).
This has two drawbacks: the first is that $T$ is often a rather large matrix, which would require significant amounts of memory to store.
In addition, reading and writing $T$ incurs a performance cost associated with reading and writing main memory.

To combat this issue, we have developed an algorithm for \gemmt{}, that is, the computation of $D \pluseq ABC$, that does not require the entire intermediate product to be stored at one time.
This algorithm exploits the blocked structure of modern matrix multiplication algorithm to only compute a cache-sized block of $(BC)$ at a time, and uses a recent algorithm that meets a theoretical lower-bound on memory I/O when the output matrix is a square that fits in the highest level of cache.
It has attained performance gains of 5--6\% (in GFlops/s) over a pair of \gemm{} calls.

\textbf{TODO, more intro?}
\section{Background}
\subsection{High-Performance \gemm{}}
Before discussing \gemmt{}, it is important to review the techniques for the operation $C \coloneqq \alpha AB + \beta C$, that is, \gemm{}.
For simplicity, we'll present the operation as $C \pluseq AB$ for simplicity.
A naive implementation would proceed as follows (where $A$ is $m$ by $k$, $B$ is $k$ by $n$, and $c$ is $m$ by $n$)
\begin{algorithm}
  \caption{Naive implementation of \gemm{}}
  \begin{algorithmic}[1]
    \Procedure{gemm}{$A, B, C$}
    \For{$i \gets 0 \textrm{ up to } m$}
    \For{$j \gets 0 \textrm{ up to } n$}
    \For{$c \gets 0 \textrm{ up to } k$}
    \Let{$C_{i, j}$}{$C_{i, j} + A_{i, c} B_{c, j}$}
    \EndFor{}
    \EndFor{}
    \EndFor{}
    \EndProcedure{}
  \end{algorithmic}
\end{algorithm}
This algorithm has serious performance issues in that it accesses the memory of one of the operands ($A$ for row-major storage and $B$ for column-major) at a stride of $k$, which is almost always a number that makes it impossible for the processor to stream both matrices' values into memory through prefectching or to vectorize the memory accesses, which would allow multiple elements of $C$ to be computed simultaneously on the same CPU core.
Therefore, it is effectively never used in practice except as a verification tool for more efficient algorithms.

Many of the high-performance \gemm{} algorithms in use today are based on the approach of Goto\textbf{TODO cite}
These algorithms massively improves performance by taking advantage of the multi-level cache present on modern CPU architectures.
They operate by reducing the \gemm{} to a series of sub-problems that are sized such that their inputs and/or outputs fit into the levels of the system's cache, and additionally by rearranging the inputs to those subploblems into a form that can be streamed from cache by the \emph{microkernel}, a highly-optimized inner loop.

One commonly-used algorithm of this type is the BLIS algorithm,

\end{document}
